# -*- coding: utf-8 -*-
"""DL Project 7 - Face Mask Detection using CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B3ilhwrGT_0WQgiKKUxsi-imuGFNTzae

1. To detect whether the person wearing a mask or not - Binary Classification Problem
2. Deep Learning Model - Convolutional Neural Network (CNN)
3. Work Flow

    * Collect Images Data - Kaggle Dataset (API)
    * Data Pre-Processing
    * Train-Test Split
    * Deep Learning Model - Convolutional Neural Network (CNN)
    * DL Model Evaluation
    * Develop Prediction System - Feed new data to trained model to predict image of either a the person wearing mask or not.
"""

# configuring the path of kaggle.json file

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

"""Importing the Dataset using API"""

# kaggle api

!kaggle datasets download -d omkargurav/face-mask-dataset

!ls

# extracting the compressed file - face-mask-dataset zip file

from zipfile import ZipFile

dataset = '/content/face-mask-dataset.zip'

with ZipFile(dataset, 'r') as zip:
  zip.extractall()
  print('The dataset is extracted')

!ls

"""Importing the Dependencies"""

import os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from PIL import Image
import cv2
from google.colab.patches import cv2_imshow
from sklearn.model_selection import train_test_split

with_mask_files = os.listdir('/content/data/with_mask')
print(with_mask_files[0:5])
print(with_mask_files[-5:])

without_mask_files = os.listdir('/content/data/without_mask')
print(without_mask_files[0:5])
print(without_mask_files[-5:])

print('Number of with mask images: ', len(with_mask_files))
print('Number of without mask images: ', len(without_mask_files))

"""Creating Labels for the Two Class of Images

* with mask --> 1

* without mask --> 0
"""

# create the labels

with_mask_label = [1] * 3725

without_mask_label = [0] * 3828

print(with_mask_label[0:5])
print(without_mask_label[0:5])

print(len(with_mask_label))
print(len(without_mask_label))

# combine two lists into one list

labels = with_mask_label + without_mask_label

print(len(labels))
print(labels[0:5])
print(labels[-5:])

"""Displaying the Images"""

# displaying with mask image

img = mpimg.imread('/content/data/with_mask/with_mask_1894.jpg')
imgplot = plt.imshow(img)
plt.show()

# displaying without mask image

img = mpimg.imread('/content/data/without_mask/without_mask_2699.jpg')
imgplot = plt.imshow(img)
plt.show()

"""Image Processing

1. Resizing the images

2. Convert the images to numpy array
"""

# convert images to numpy array + resize the images + convert the grayscale images to RGB images

with_mask_path = '/content/data/with_mask/'

data = []

for img_file in with_mask_files:

  image = Image.open(with_mask_path + img_file)
  image = image.resize((128,128))
  image = image.convert('RGB')
  image = np.array(image)

  data.append(image)



without_mask_path = '/content/data/without_mask/'

for img_file in without_mask_files:

  image = Image.open(without_mask_path + img_file)
  image = image.resize((128,128))
  image = image.convert('RGB')
  image = np.array(image)

  data.append(image)

type(data)

len(data)

data[0]

type(data[0])

data[0].shape

# converting the image list (data) and labels list to numpy array

X = np.array(data)
Y = np.array(labels)

type(X)

type(Y)

print(X.shape)
print(Y.shape)

"""Train-Test Split"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

"""Scaling / Normalization"""

# scaling the data

X_train_scaled = X_train/255
X_test_scaled = X_test/255

X_train[0]

X_train_scaled[0]

"""Model Training - Convolutional Neural Network (CNN)"""

import tensorflow as tf
from tensorflow import keras # keras is not a stand-alone library - keras need tensorflow/pytorch as backend library

num_of_classes = 2

model = keras.Sequential()

# first conv layer
model.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(128,128,3)))
model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))

# second conv layer
model.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))
model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))

# input layer
model.add(keras.layers.Flatten())

# first hidden layer
model.add(keras.layers.Dense(128, activation='relu'))
model.add(keras.layers.Dropout(0.5))

# second hidden layer
model.add(keras.layers.Dense(64, activation='relu'))
model.add(keras.layers.Dropout(0.5))

# output layer
model.add(keras.layers.Dense(num_of_classes, activation='sigmoid'))

# compile the neural network (NN)

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['acc'])

# model training

history = model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs=5)

"""Model Evaluation"""

loss, accuracy = model.evaluate(X_test_scaled, Y_test)
print('Test accuracy = ', accuracy)

# visualizing the loss and accuracy

h = history

# plot the loss value

plt.plot(h.history['loss'], label='train loss')
plt.plot(h.history['val_loss'], label='validation loss')
plt.legend()
plt.show()

# plot the accuracy value

plt.plot(h.history['acc'], label='train accuracy')
plt.plot(h.history['val_acc'], label='validation accuracy')
plt.legend()
plt.show()

"""Predictive System"""

input_image_path = input('Path of the image to be predicted: ')

input_image = cv2.imread(input_image_path)

cv2_imshow(input_image)

input_image_resize = cv2.resize(input_image, (128,128))

input_image_scaled = input_image_resize/255

input_image_reshaped = np.reshape(input_image_scaled, [1, 128, 128, 3])

input_prediction = model.predict(input_image_reshaped)

print(input_prediction)


input_pred_label = np.argmax(input_prediction)

print(input_pred_label)


if input_pred_label == 1:
  print('The person is wearing a mask')

else:
  print('The person is not wearing a mask')