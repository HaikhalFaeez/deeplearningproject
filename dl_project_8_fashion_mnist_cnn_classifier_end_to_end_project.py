# -*- coding: utf-8 -*-
"""DL Project 8 - Fashion MNIST CNN Classifier - End-to-End Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xr5T5loGqz_3uMjI1TisIctw4USaJ4Mo

1.  To classify the fashion image according to the class available in the dataset
2.  Deep Learning Model -Convolutional Neural Network (CNN)
3.  Work Flow

    *   Collect Image Fashion Sample Data - Tensorflow Dataset
    *   Data Pre-Processing
    *   Train-Test Split
    *   Deep Learning Model -Convolutional Neural Network (CNN)
    *   DL Model Evaluation
    *   Streamlit Web App
    *   Dockerized
        - Dockerfile (Create docker file containing list of instruction that need to give to build docker image from the code)
        - Docker Image (Build docker image which act as a base image for the docker container)
        - Docker Container (Run to get the streamlit web app)


    *   Develop Prediction System - Feed new data to trained model to predict image of either an airplane, automobile, bird, cat, deer, dog, frog, horse, ship or truck.

Seeding the reproducility
"""

# Set seeds for reproducility - avoid randomness and maintain stability
import random
random.seed(0)

import numpy as np
np.random.seed(0)

import tensorflow as tf
tf.random.set_seed(0)

"""Importing the Dependencies"""

from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

"""Data Curation"""

# Load and prepare the Fashion MNIST dataset
fashion_mnist = datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

"""Data/Image Processing"""

type(train_images)
type(train_labels)

print(len(train_images))
print(len(train_labels))

print(train_images[0].shape)

print(type(train_images[0])) # already processed by tensorflow (convert to numpy array)

print(train_images[0])

# displaying the image

plt.imshow(train_images[0], cmap='gray')
plt.show()

# print the corresponding label
print(train_labels[0])

"""class names/labels:

1 - Tshirt/top

2 - Trouser

3 - Pullover

4 - Dress

5 - Coat

6 - Sandal

7 - Shirt

8 - Sneaker

9 - Bag

10 - Ankle Boot
"""

# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0

# Reshape images to specify that it's a single channel (grayscale)
train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))
test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))

"""Convolutional Neural Network (CNN)"""

# Build the convolutional base
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64, (3,3), activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64, (3,3), activation='relu'))

# Add Dense layers on top
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10))

# Compile the model
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

"""Model Training"""

history = model.fit(train_images, train_labels, epochs=5,
                    validation_data=(test_images, test_labels))

"""Model Evaluation"""

# Evaluate the model
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
print('\nTest accuracy: ', test_acc)

# Plot training & vaidation accuracy values
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()